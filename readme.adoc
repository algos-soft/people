:doctype: article
:doctitle: People application
:!toc:

The application provides an endpoint to upload .csv files to a database and a simple monitoring UI.

It has been implemented as a SpringBoot application with some open source libraries added to simplify common tasks.

==== Libraries used
The main libraries added to *SpringBoot* are:

- *h2 database*, as the implementation of Spring JPA

- *vaadin*, in order to build a quick and simple UI

- *apache commons-csv*, for parsing the csv format

- *apache tika*, for mime type detection

- *okhttp* and *moshi*, for the sample data generator

==== Requirements:

JRE 8.x and Maven must be available

==== Installation:
- unzip the provided package

- cd to the project directory and run:

....
mvn clean package -Pproduction
....

NOTE: In case you get an error complying about Node version (it may happen on some old Unix systems) run the command: *mvn com.github.eirslett:frontend-maven-plugin:1.7.6:install-node-and-npm -DnodeVersion="v12.14.0"* and retry the operation.


==== Running the application:
cd to the project directory and run:

....
java -jar target/people-1.0-SNAPSHOT.jar
....

(when the server is ready you can connect to the UI at http://localhost:8080)


==== Usage
Submit the csv files via http POSTs of type form-data to the endpoint http://localhost:8080/people/submit

example with curl:
....
curl --location --request POST http://localhost:8080/people/submit --form file=@<myfile.csv>
....

NOTE: You can find some example files in the *testfiles* directory

==== Notes

===== Persistence layer
The persistence implementation is based on the H2 database and Spring Data JPA (the persistence layer can easily be changed by providing different implementations of the Repository interfaces).

The database is stored in memory. You can store it on a file enabling the appropriate property in config/application.properties.

===== CSV implementation
CSV is an old format and comes in various flavors. Since the actual flavor was not specified, the standard format defined in RFC 4180 has been implemented (using commas as separators).
The parser used is Apache Commons CSV.

===== Email field uniqueness
Due to the uniqueness constraint on the email field, a unique index has been added at persistence level.

....
Person.class -> @Table(indexes = @Index(columnList = "email"))
....

===== Date format problem
The guidelines didn't specify the format for the date field, so a brute force parser had to be used in order to support different possible date formats.

A more efficient solution could be used if some specs on the date format were provided.

===== .txt file type problem
[quote]
"Given a new file to import, when I upload a *.txt file, then I should receive an error"

This requirement was a bit misleading.

Although it is possible to detect the original filename, a .txt extension doesn't mean that the file does not contain a valid csv structure, and in the other hand a .csv extension does not guarantee to contain a valid csv content.

The check on the .txt extension has been implemented, but another check was added, which detects the MIME type of the content through Apache Tika, in order to reject any non "text/plain" content.

===== Handling of invalid data
In case of malformed csv or missing email, the whole import operation is interrupted. Other strategies which could be implemented may include rolling back the transaction or skipping the invalid entries.

===== Error handling
Generally, all the errors are logged at service level with detailed technical information and error stacktrace.

At a higher level (controller level), the errors are catched, grouped and returned with a level of detail meaningful to the client application.

The client will then decide if and how to notify the user in case of error.

===== Unit testing
Only the classes relevant to this exercise have been tested, namely *PeopleController* and *PersonsService*. Inside these classes, only the public methods have been tested, since the private methods are considered private implementation details and are already tested through the public methods.

===== Random user generator
In order to test the endpoint, some .csv files with random people and different sizes were needed, so a small service based on randomuser.me has been implemented to generate them.

You can access the generator service at http://localhost:8080/generator if you are interested.

===== Test data
In the *testfiles* directory you can find different data files already prepared for testing.

NOTE: Note: the sample 10.000 rows datafile does not produce 10.000 rows in the database because some email addresses are duplicated.
